{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hired-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kshahin/miniconda2/envs/hera3/lib/python3.7/site-packages/hera_sim/visibilities/__init__.py:22: UserWarning: HealVis failed to import.\n",
      "  warnings.warn(\"HealVis failed to import.\")\n",
      "/users/kshahin/miniconda2/envs/hera3/lib/python3.7/site-packages/hera_sim/visibilities/__init__.py:27: UserWarning: PRISim failed to import.\n",
      "  warnings.warn(\"PRISim failed to import.\")\n",
      "/users/kshahin/miniconda2/envs/hera3/lib/python3.7/site-packages/hera_sim/visibilities/__init__.py:33: UserWarning: VisGPU failed to import.\n",
      "  warnings.warn(\"VisGPU failed to import.\")\n",
      "/users/kshahin/miniconda2/envs/hera3/lib/python3.7/site-packages/hera_sim/__init__.py:36: FutureWarning: \n",
      "In the next major release, all HERA-specific variables will be removed from the codebase. The following variables will need to be accessed through new class-like structures to be introduced in the next major release: \n",
      "\n",
      "noise.HERA_Tsky_mdl\n",
      "noise.HERA_BEAM_POLY\n",
      "sigchain.HERA_NRAO_BANDPASS\n",
      "rfi.HERA_RFI_STATIONS\n",
      "\n",
      "Additionally, the next major release will involve modifications to the package's API, which move toward a regularization of the way in which hera_sim methods are interfaced with; in particular, changes will be made such that the Simulator class is the most intuitive way of interfacing with the hera_sim package features.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hera_cal.abscal as abscal\n",
    "import uvtools.dspec as dspec \n",
    "import hera_pspec\n",
    "from hera_pspec import pspecbeam\n",
    "from hera_pspec import pspecdata\n",
    "import itertools\n",
    "import scipy \n",
    "from scipy import signal\n",
    "import pickle\n",
    "import copy\n",
    "from hera_cal.utils import polnum2str, polstr2num, jnum2str, jstr2num\n",
    "from hera_cal.io import HERAData, HERACal\n",
    "from hera_cal.io import DataContainer \n",
    "from hera_cal import apply_cal\n",
    "from hera_cal import io\n",
    "from hera_cal import smooth_cal\n",
    "from hera_cal import vis_clean\n",
    "from hera_cal import redcal\n",
    "from pyuvdata import UVFlag\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from hera_cal import frf\n",
    "import imp\n",
    "from hera_pspec import utils as uvp_utils\n",
    "from hera_pspec import plot as pspec_plot\n",
    "from hera_pspec import grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exceptional-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data, Model, and Flags\n",
    "\n",
    "flag_files = [f\"H1C_Flags/{jd}.flags.h5\" for jd in [2458098,2458099,2458101,2458102,2458103,2458104,2458105,2458106,\n",
    "                                                    2458107,2458108,2458109,2458110,2458111,2458112,2458113,2458114,\n",
    "                                                    2458115,2458116]]\n",
    "model_files = sorted(glob.glob('/lustre/aoc/projects/hera/aewallwi/time_dep_flagging/2458098/*.true.uvh5'))\n",
    "data_files = sorted(glob.glob('/lustre/aoc/projects/hera/aewallwi/time_dep_flagging/2458098/*.true.uvh5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dirty-shape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Days 18\n",
      "Number of Chunks 32\n"
     ]
    }
   ],
   "source": [
    "#Calculate Number of Days and Chunks\n",
    "nfiles = []\n",
    "for day,flag_file in enumerate(flag_files):\n",
    "    file_number=0\n",
    "    for data_file in zip(data_files):\n",
    "        file_number += 1\n",
    "    nfiles.append(file_number)\n",
    "print('Number of Days',len(nfiles))\n",
    "print('Number of Chunks',file_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Before Filter (ABF)\n",
    "\n",
    "if not os.path.exists(f'AverageBeforeFilter'):\n",
    "        os.mkdir(f'AverageBeforeFilter')\n",
    "for file_number in range(len(nfiles)):\n",
    "    for day in range(len(flag_files)):\n",
    "        cfile = f\"Day_{day}/data_{day}_{file_number}_smoothcal.uvh5\"\n",
    "        hd = HERAData(cfile)\n",
    "        data_t,flags_t,nsamples_t = hd.read()\n",
    "        #Load First Day\n",
    "        if day==0:\n",
    "            data_avg=DataContainer({bl:data_t[bl]*nsamples_t[bl]*(~flags_t[bl]) for bl in data_t})\n",
    "            flags_avg =DataContainer({bl:flags_t[bl] for bl in data_t})\n",
    "            nsamples_avg = DataContainer({bl:nsamples_t[bl]*(~flags_t[bl]) for bl in data_t})\n",
    "        #Average Following Days\n",
    "        else:\n",
    "            for bl in data_avg:\n",
    "                data_avg[bl] = data_avg[bl] + data_t[bl]*nsamples_t[bl]*(~flags_t[bl])\n",
    "                flags_avg[bl] = flags_avg[bl] & flags_t[bl]\n",
    "                nsamples_avg[bl] = nsamples_avg[bl] + nsamples_t[bl]*(~flags_t[bl])           \n",
    "    for bl in data_avg:   \n",
    "        data_avg[bl] = data_avg[bl]/nsamples_avg[bl]\n",
    "        data_avg[bl][~np.isfinite(data_avg[bl])] = 0.0\n",
    "    hd.update(data=data_avg, flags=flags_avg, nsamples=nsamples_avg)\n",
    "    hd.write_uvh5(f'AverageBeforeFilter/data_avg_{file_number}.uvh5', clobber=True)\n",
    "    \n",
    "#Fourier Filter\n",
    "for file_number in range(len(nfiles)):\n",
    "    vc = vis_clean.VisClean(f'AverageBeforeFilter/data_avg_{file_number}.uvh5')\n",
    "    vc.read()\n",
    "    vc.vis_clean(standoff=100, min_dly=600, mode='dpss_leastsq', skip_if_flag_within_edge_distance=1,\n",
    "                 flag_model_rms_outliers=True, max_contiguous_edge_flags=1)\n",
    "    vc.write_filtered_data(filled_outfilename=f'AverageBeforeFilter/data_avg_{file_number}_filtered.uvh5',\n",
    "                           clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average After Filter (AAF)\n",
    "\n",
    "if not os.path.exists(f'AverageAfterFilter'):\n",
    "        os.mkdir(f'AverageAfterFilter')\n",
    "for file_number in range(len(nfiles)):\n",
    "    for day in range(len(flag_files)):\n",
    "        ffile = f\"Day_{day}/data_{day}_{file_number}_filtered.uvh5\"\n",
    "        hd = HERAData(ffile)\n",
    "        data_f,flags_f,nsamples_f = hd.read()\n",
    "        #Load First Day\n",
    "        if day==0:\n",
    "            data_avg=DataContainer({bl:data_f[bl]*nsamples_f[bl]*(~flags_f[bl]) for bl in data_f})\n",
    "            flags_avg =DataContainer({bl:flags_f[bl] for bl in data_f})\n",
    "            nsamples_avg = DataContainer({bl:nsamples_f[bl]*(~flags_f[bl]) for bl in data_f})\n",
    "        #Average Following Days\n",
    "        else:\n",
    "            for bl in data_avg:\n",
    "                data_avg[bl] = data_avg[bl] + data_f[bl]*nsamples_f[bl]*(~flags_f[bl])\n",
    "                flags_avg[bl] = flags_avg[bl] & flags_f[bl]\n",
    "                nsamples_avg[bl] = nsamples_avg[bl] + nsamples_f[bl]*(~flags_f[bl])\n",
    "    for bl in data_avg:   \n",
    "        data_avg[bl] = data_avg[bl]/nsamples_avg[bl]\n",
    "        data_avg[bl][~np.isfinite(data_avg[bl])] = 0.0\n",
    "    hd.update(data=data_avg, flags=flags_avg, nsamples=nsamples_avg)\n",
    "    hd.write_uvh5(f'AverageAfterFilter/data_avg_{file_number}_filtered.uvh5', clobber=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining Chunks(Time Averaging) of ABF & AAF Days\n",
    "\n",
    "cavg_before = sorted(glob.glob('AverageBeforeFilter/data_avg_*_filtered.uvh5'))\n",
    "frf.time_avg_data_and_write(cavg_before,\n",
    "                            output_data='AverageBeforeFilter/data_avg.Cavg.uvh5',\n",
    "                            t_avg=300, rephase=True, clobber=True, wgt_by_nsample=False)\n",
    "\n",
    "cavg_after = sorted(glob.glob('AverageAfterFilter/data_avg_*_filtered.uvh5'))\n",
    "frf.time_avg_data_and_write(cavg_after,\n",
    "                            output_data='AverageAfterFilter/data_avg.Cavg.uvh5',\n",
    "                            t_avg=300, rephase=True, clobber=True,wgt_by_nsample=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
